{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch tutorial\n",
    "\n",
    "\n",
    "![](https://miro.medium.com/max/1000/0*1HWz9KQ-duZZykT7.png)\n",
    "\n",
    "\n",
    "reference : https://pytorch.org/docs/master/torch.html\n",
    "https://datascienceschool.net/view-notebook/4f3606fd839f4320a4120a56eec1e228/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-26T18:59:16.141254Z",
     "start_time": "2020-07-26T18:59:16.131507Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-60edeab97733>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-60edeab97733>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    _ inplace true\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "_ inplace true "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Create-Tensor\" data-toc-modified-id=\"Create-Tensor-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Create Tensor</a></span><ul class=\"toc-item\"><li><span><a href=\"#Zeros,-ones,-arrange\" data-toc-modified-id=\"Zeros,-ones,-arrange-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Zeros, ones, arrange</a></span></li></ul></li><li><span><a href=\"#TORCH.TENSOR\" data-toc-modified-id=\"TORCH.TENSOR-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>TORCH.TENSOR</a></span></li><li><span><a href=\"#Numpy-to-Tensor-&amp;-Tensor-toNumpy\" data-toc-modified-id=\"Numpy-to-Tensor-&amp;-Tensor-toNumpy-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Numpy to Tensor &amp; Tensor toNumpy</a></span><ul class=\"toc-item\"><li><span><a href=\"#Numpy--->-Tensor\" data-toc-modified-id=\"Numpy--->-Tensor-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Numpy --&gt; Tensor</a></span></li></ul></li><li><span><a href=\"#Indexing,-Slicing,-Joining\" data-toc-modified-id=\"Indexing,-Slicing,-Joining-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Indexing, Slicing, Joining</a></span></li><li><span><a href=\"#Joining\" data-toc-modified-id=\"Joining-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Joining</a></span><ul class=\"toc-item\"><li><span><a href=\"#Slicing\" data-toc-modified-id=\"Slicing-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Slicing</a></span></li><li><span><a href=\"#squeezing\" data-toc-modified-id=\"squeezing-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>squeezing</a></span></li></ul></li><li><span><a href=\"#Math-operations\" data-toc-modified-id=\"Math-operations-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Math operations</a></span><ul class=\"toc-item\"><li><span><a href=\"#torch.add()\" data-toc-modified-id=\"torch.add()-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>torch.add()</a></span></li><li><span><a href=\"#torch.mul()\" data-toc-modified-id=\"torch.mul()-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>torch.mul()</a></span></li><li><span><a href=\"#torch.pow\" data-toc-modified-id=\"torch.pow-6.3\"><span class=\"toc-item-num\">6.3&nbsp;&nbsp;</span>torch.pow</a></span></li></ul></li><li><span><a href=\"#log\" data-toc-modified-id=\"log-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>log</a></span></li><li><span><a href=\"#Matrix-operator\" data-toc-modified-id=\"Matrix-operator-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Matrix operator</a></span></li><li><span><a href=\"#Tensor-on-CPU-&amp;-GPU\" data-toc-modified-id=\"Tensor-on-CPU-&amp;-GPU-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Tensor on CPU &amp; GPU</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Tensor\n",
    "### Zeros, ones, arrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max and min and mean and std ã……"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-23T05:03:08.227468Z",
     "start_time": "2020-07-23T05:03:05.016299Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T07:37:41.419562Z",
     "start_time": "2020-07-21T07:37:41.369563Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make 2-by-3 tensor\n",
    "X = torch.zeros(2,3)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T07:37:41.463563Z",
     "start_time": "2020-07-21T07:37:41.438563Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1 = torch.ones(2,3)\n",
    "X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T07:37:41.490563Z",
     "start_time": "2020-07-21T07:37:41.482562Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.5000, 1.0000, 1.5000, 2.0000, 2.5000])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.arange(start,end,step=1) -> [start,end) with step\n",
    "x = torch.arange(0,3,step=0.5)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TORCH.TENSOR\n",
    "> A `torch.Tensor` is a multi-dimensional matrix containing elements of a single data type.\n",
    "> Torch defines nine `CPU tensor` types and nine `GPU tensor` types:\n",
    "\n",
    "<table class=\"docutils align-default\">\n",
    "<colgroup>\n",
    "<col style=\"width: 19%\">\n",
    "<col style=\"width: 34%\">\n",
    "<col style=\"width: 21%\">\n",
    "<col style=\"width: 25%\">\n",
    "</colgroup>\n",
    "<thead>\n",
    "<tr class=\"row-odd\"><th class=\"head\"><p>Data type</p></th>\n",
    "<th class=\"head\"><p>dtype</p></th>\n",
    "<th class=\"head\"><p>CPU tensor</p></th>\n",
    "<th class=\"head\"><p>GPU tensor</p></th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr class=\"row-even\"><td><p>32-bit floating point</p></td>\n",
    "<td><p><code class=\"docutils literal notranslate\"><span class=\"pre\">torch.float32</span></code> or <code class=\"docutils literal notranslate\"><span class=\"pre\">torch.float</span></code></p></td>\n",
    "<td><p><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">torch.FloatTensor</span></code></p></td>\n",
    "<td><p><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">torch.cuda.FloatTensor</span></code></p></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><p>64-bit floating point</p></td>\n",
    "<td><p><code class=\"docutils literal notranslate\"><span class=\"pre\">torch.float64</span></code> or <code class=\"docutils literal notranslate\"><span class=\"pre\">torch.double</span></code></p></td>\n",
    "<td><p><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">torch.DoubleTensor</span></code></p></td>\n",
    "<td><p><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">torch.cuda.DoubleTensor</span></code></p></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><p>16-bit floating point</p></td>\n",
    "<td><p><code class=\"docutils literal notranslate\"><span class=\"pre\">torch.float16</span></code> or <code class=\"docutils literal notranslate\"><span class=\"pre\">torch.half</span></code></p></td>\n",
    "<td><p><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">torch.HalfTensor</span></code></p></td>\n",
    "<td><p><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">torch.cuda.HalfTensor</span></code></p></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><p>8-bit integer (unsigned)</p></td>\n",
    "<td><p><code class=\"docutils literal notranslate\"><span class=\"pre\">torch.uint8</span></code></p></td>\n",
    "<td><p><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">torch.ByteTensor</span></code></p></td>\n",
    "<td><p><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">torch.cuda.ByteTensor</span></code></p></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><p>8-bit integer (signed)</p></td>\n",
    "<td><p><code class=\"docutils literal notranslate\"><span class=\"pre\">torch.int8</span></code></p></td>\n",
    "<td><p><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">torch.CharTensor</span></code></p></td>\n",
    "<td><p><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">torch.cuda.CharTensor</span></code></p></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><p>16-bit integer (signed)</p></td>\n",
    "<td><p><code class=\"docutils literal notranslate\"><span class=\"pre\">torch.int16</span></code> or <code class=\"docutils literal notranslate\"><span class=\"pre\">torch.short</span></code></p></td>\n",
    "<td><p><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">torch.ShortTensor</span></code></p></td>\n",
    "<td><p><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">torch.cuda.ShortTensor</span></code></p></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><p>32-bit integer (signed)</p></td>\n",
    "<td><p><code class=\"docutils literal notranslate\"><span class=\"pre\">torch.int32</span></code> or <code class=\"docutils literal notranslate\"><span class=\"pre\">torch.int</span></code></p></td>\n",
    "<td><p><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">torch.IntTensor</span></code></p></td>\n",
    "<td><p><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">torch.cuda.IntTensor</span></code></p></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><p>64-bit integer (signed)</p></td>\n",
    "<td><p><code class=\"docutils literal notranslate\"><span class=\"pre\">torch.int64</span></code> or <code class=\"docutils literal notranslate\"><span class=\"pre\">torch.long</span></code></p></td>\n",
    "<td><p><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">torch.LongTensor</span></code></p></td>\n",
    "<td><p><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">torch.cuda.LongTensor</span></code></p></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><p>Boolean</p></td>\n",
    "<td><p><code class=\"docutils literal notranslate\"><span class=\"pre\">torch.bool</span></code></p></td>\n",
    "<td><p><a class=\"reference internal has-code\" href=\"#torch.BoolTensor\" title=\"torch.BoolTensor\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">torch.BoolTensor</span></code></a></p></td>\n",
    "<td><p><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">torch.cuda.BoolTensor</span></code></p></td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T07:39:24.832818Z",
     "start_time": "2020-07-21T07:39:24.826817Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.FloatTensor\n",
      "tensor([[0.0000e+00, 0.0000e+00, 1.0570e+21],\n",
      "        [1.6969e-07, 1.0533e+21, 5.3642e-08]])\n"
     ]
    }
   ],
   "source": [
    "# torch.FloatTensor(size or list)\n",
    "x = torch.FloatTensor(2,3)\n",
    "print(x.type())\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T07:39:30.767644Z",
     "start_time": "2020-07-21T07:39:30.761643Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.IntTensor\n",
      "tensor([[          0,           0, -2147483648],\n",
      "        [          0, -2147483648,           0]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "# tensor.type_as(tensor_type)\n",
    "x = x.type_as(torch.IntTensor())\n",
    "print(x.type())\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy to Tensor & Tensor toNumpy \n",
    "\n",
    "### Numpy --> Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T08:47:49.242600Z",
     "start_time": "2020-07-21T08:47:49.236599Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.3371e+22, 4.1959e-08, 2.6851e-06],\n",
       "        [1.6785e-07, 1.0442e-08, 1.0548e-08]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.FloatTensor(2,3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T07:45:03.827067Z",
     "start_time": "2020-07-21T07:45:03.810067Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0],\n",
       "       [0, 0, 0]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "# define numpy \n",
    "x1 = np.random.rand(2,3,).astype(int)\n",
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T07:45:20.608599Z",
     "start_time": "2020-07-21T07:45:20.602599Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0],\n",
       "        [0, 0, 0]], dtype=torch.int32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert to tensor\n",
    "x2 = torch.from_numpy(x1)\n",
    "print(x2.type())\n",
    "print(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T07:46:30.432350Z",
     "start_time": "2020-07-21T07:46:30.416719Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0],\n",
       "       [0, 0, 0]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.tensor--> numpy \n",
    "x2.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing, Slicing, Joining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-23T05:06:07.301943Z",
     "start_time": "2020-07-23T05:06:07.246945Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2756, 0.2484],\n",
       "        [0.6346, 0.9609],\n",
       "        [0.8173, 0.1188],\n",
       "        [0.8398, 0.5247]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# indexing \n",
    "# torch.index_select(input, dim, index)\n",
    "x = torch.rand(4,3)\n",
    "indices = torch.tensor([0, 2])\n",
    "# row \n",
    "torch.index_select(x, 0, indices)\n",
    "# columns\n",
    "torch.index_select(x, 1, indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pythonic indexing\n",
    "\n",
    "x[:,0]\n",
    "x[0,:]\n",
    "x[0:2,0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.masked_select(input, mask)\n",
    "\n",
    "x = torch.randn(2,3)\n",
    "mask = torch.ByteTensor([[0,0,1],[0,1,0]])\n",
    "out = torch.masked_select(x,mask)\n",
    "\n",
    "x, mask, out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-23T05:21:06.424144Z",
     "start_time": "2020-07-23T05:21:06.384143Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3.],\n",
       "         [4., 5., 6.]]),\n",
       " tensor([[-1., -2., -3.],\n",
       "         [-4., -5., -6.]]),\n",
       " tensor([[ 1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.],\n",
       "         [-1., -2., -3.],\n",
       "         [-4., -5., -6.]]),\n",
       " tensor([[ 1.,  2.,  3., -1., -2., -3.],\n",
       "         [ 4.,  5.,  6., -4., -5., -6.]]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.cat(seq, dim=0) -> concatenate tensor along dim\n",
    "\n",
    "x = torch.FloatTensor([[1,2,3],[4,5,6]])\n",
    "y = torch.FloatTensor([[-1,-2,-3],[-4,-5,-6]])\n",
    "z1 = torch.cat([x,y],dim=0)\n",
    "z2 = torch.cat([x,y],dim=1)\n",
    "\n",
    "x,y,z1,z2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-23T05:22:12.945589Z",
     "start_time": "2020-07-23T05:22:12.935590Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 2., 3.],\n",
       "         [4., 5., 6.]],\n",
       "\n",
       "        [[1., 2., 3.],\n",
       "         [4., 5., 6.]],\n",
       "\n",
       "        [[1., 2., 3.],\n",
       "         [4., 5., 6.]],\n",
       "\n",
       "        [[1., 2., 3.],\n",
       "         [4., 5., 6.]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.stack(sequence,dim=0) -> stack along new dim\n",
    "\n",
    "x = torch.FloatTensor([[1,2,3],[4,5,6]])\n",
    "x_stack = torch.stack([x,x,x,x],dim=0)\n",
    "\n",
    "x_stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slicing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chunk or split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-23T05:27:58.199648Z",
     "start_time": "2020-07-23T05:27:58.194648Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.,  3.],\n",
       "        [ 4.,  5.,  6.],\n",
       "        [-1., -2., -3.],\n",
       "        [-4., -5., -6.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-23T05:27:54.300649Z",
     "start_time": "2020-07-23T05:27:54.125649Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3.],\n",
       "         [4., 5., 6.]]),\n",
       " tensor([[-1., -2., -3.],\n",
       "         [-4., -5., -6.]]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.chunk(tensor, chunks, dim=0) -> tensor into num chunks\n",
    "\n",
    "x_1, x_2 = torch.chunk(z1,2,dim=0)\n",
    "x_1, x_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-23T05:30:12.057678Z",
     "start_time": "2020-07-23T05:30:12.050679Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3.],\n",
       "         [4., 5., 6.]]),\n",
       " tensor([[-1., -2., -3.],\n",
       "         [-4., -5., -6.]]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "x_1, x_2 = torch.split(z1,2,dim=0)\n",
    "x_1, x_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_1, y_2, y_3 = torch.chunk(z1,3,dim=1)\n",
    "\n",
    "z1,x_1,x_2,z1,y_1,y_2,y_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.split(tensor,split_size,dim=0) -> split into specific size\n",
    "\n",
    "x1,x2 = torch.split(z1,2,dim=0)\n",
    "y1 = torch.split(z1,2,dim=1) \n",
    "\n",
    "z1,x1,x2,y1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### squeezing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.squeeze(input,dim=None) -> reduce dim by 1\n",
    "\n",
    "x1 = torch.FloatTensor(10,1,3,1,4)\n",
    "x2 = torch.squeeze(x1)\n",
    "\n",
    "x1.size(),x2.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.unsqueeze(input,dim=None) -> add dim by 1\n",
    "\n",
    "x1 = torch.FloatTensor(10,3,4)\n",
    "x2 = torch.unsqueeze(x1,dim=0)\n",
    "\n",
    "x1.size(),x2.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Math operations\n",
    "\n",
    "pointwise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.add()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T08:23:13.156478Z",
     "start_time": "2020-07-21T08:23:13.140477Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3.],\n",
       "         [4., 5., 6.]]),\n",
       " tensor([[1., 2., 3.],\n",
       "         [4., 5., 6.]]),\n",
       " tensor([[ 2.,  4.,  6.],\n",
       "         [ 8., 10., 12.]]),\n",
       " tensor([[ 2.,  4.,  6.],\n",
       "         [ 8., 10., 12.]]),\n",
       " tensor([[0., 0., 0.],\n",
       "         [0., 0., 0.]]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.add()\n",
    "x1 = torch.FloatTensor([[1,2,3],[4,5,6]])\n",
    "x2 = torch.FloatTensor([[1,2,3],[4,5,6]])\n",
    "add = torch.add(x1,x2)\n",
    "\n",
    "x1,x2,add,x1+x2,x1-x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T08:34:55.267710Z",
     "start_time": "2020-07-21T08:34:55.255710Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3.],\n",
       "         [4., 5., 6.]]),\n",
       " tensor([[11., 12., 13.],\n",
       "         [14., 15., 16.]]),\n",
       " tensor([[11., 12., 13.],\n",
       "         [14., 15., 16.]]),\n",
       " tensor([[1., 2., 3.],\n",
       "         [4., 5., 6.]]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.add() pointwise addtion\n",
    "x1 = torch.FloatTensor([[1,2,3],[4,5,6]])\n",
    "x2 = torch.add(x1,10)\n",
    "\n",
    "x1,x2,x1+10,x2-10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.mul()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.mul() -> size better match\n",
    "\n",
    "x1 = torch.FloatTensor([[1,2,3],[4,5,6]])\n",
    "x2 = torch.FloatTensor([[1,2,3],[4,5,6]])\n",
    "x3 = torch.mul(x1,x2)\n",
    "\n",
    "x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.div() -> broadcasting\n",
    "\n",
    "x1 = torch.FloatTensor([[1,2,3],[4,5,6]])\n",
    "\n",
    "x1/5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.pow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.pow(base,exponent)\n",
    "x1 = torch.FloatTensor(3,4)\n",
    "torch.pow(x1,2),x1**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T08:46:51.712991Z",
     "start_time": "2020-07-21T08:46:51.681737Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.exp(tensor,out=None) \n",
    "\n",
    "x1 = torch.FloatTensor(3,4)\n",
    "print(x1)\n",
    "torch.exp(x1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## log\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.log(input, out=None) -> natural logarithm\n",
    "\n",
    "x1 = torch.FloatTensor(3,4)\n",
    "torch.log(x1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.mm(mat1, mat2) -> matrix multiplication\n",
    "\n",
    "x1 = torch.FloatTensor(3,4)\n",
    "x2 = torch.FloatTensor(4,5)\n",
    "\n",
    "torch.mm(x1,x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.dot(tensor1,tensor2) -> dot product of two tensor\n",
    "\n",
    "x1 = torch.FloatTensor(3,4)\n",
    "x2 = torch.FloatTensor(3,4)\n",
    "\n",
    "torch.dot(x1,x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.t(matrix) -> transposed matrix\n",
    "\n",
    "x1 = torch.FloatTensor(3,4)\n",
    "\n",
    "x1,x1.t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.transpose(input,dim0,dim1) -> transposed matrix\n",
    "\n",
    "x1 = torch.FloatTensor(10,3,4)\n",
    "\n",
    "x1.size(), torch.transpose(x1,1,2).size(), x1.transpose(1,2).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TORCH.BMM\n",
    "torch.bmm(input, mat2, deterministic=False, out=None) â†’ Tensor\n",
    "Performs a batch matrix-matrix product of matrices stored in input and mat2.\n",
    "\n",
    "input and mat2 must be 3-D tensors each containing the same number of matrices.\n",
    "\n",
    "If input is a (b \\times n \\times m)(bÃ—nÃ—m) tensor, mat2 is a (b \\times m \\times p)(bÃ—mÃ—p) tensor, out will be a (b \\times n \\times p)(bÃ—nÃ—p) tensor.\n",
    "\n",
    "\\text{out}_i = \\text{input}_i \\mathbin{@} \\text{mat2}_i\n",
    "\n",
    "This function does not broadcast. For broadcasting matrix products, see torch.matmul()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.bmm(batch1, batch2) -> batch matrix multiplication\n",
    "\n",
    "x1 = torch.FloatTensor(10,3,4)\n",
    "x2 = torch.FloatTensor(10,4,5)\n",
    "\n",
    "torch.bmm(x1,x2).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.eig(a,eigenvectors=False) -> eigen_value, eigen_vector\n",
    "\n",
    "x1 = torch.FloatTensor(4,4)\n",
    "\n",
    "x1,torch.eig(x1,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor on CPU & GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T08:18:01.731441Z",
     "start_time": "2020-07-21T08:18:01.722440Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cpu tensor\n",
    "x = torch.FloatTensor([[1,2,3],[4,5,6]])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T08:22:02.676671Z",
     "start_time": "2020-07-21T08:22:02.663670Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "\nThe NVIDIA driver on your system is too old (found version 9010).\nPlease update your GPU driver by downloading and installing a new\nversion from the URL: http://www.nvidia.com/Download/index.aspx\nAlternatively, go to: https://pytorch.org to install\na PyTorch version that has been compiled with your version\nof the CUDA driver.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-68f0de7be6de>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# cpu to gpu\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mx_gpu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mx_gpu\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\cuda\\__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    147\u001b[0m             raise RuntimeError(\n\u001b[0;32m    148\u001b[0m                 \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\n\u001b[1;32m--> 149\u001b[1;33m         \u001b[0m_check_driver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    150\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_cudart\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m             raise AssertionError(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\cuda\\__init__.py\u001b[0m in \u001b[0;36m_check_driver\u001b[1;34m()\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[0mAlternatively\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgo\u001b[0m \u001b[0mto\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mhttps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m//\u001b[0m\u001b[0mpytorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0morg\u001b[0m \u001b[0mto\u001b[0m \u001b[0minstall\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[0ma\u001b[0m \u001b[0mPyTorch\u001b[0m \u001b[0mversion\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mhas\u001b[0m \u001b[0mbeen\u001b[0m \u001b[0mcompiled\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0myour\u001b[0m \u001b[0mversion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m of the CUDA driver.\"\"\".format(str(torch._C._cuda_getDriverVersion())))\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: \nThe NVIDIA driver on your system is too old (found version 9010).\nPlease update your GPU driver by downloading and installing a new\nversion from the URL: http://www.nvidia.com/Download/index.aspx\nAlternatively, go to: https://pytorch.org to install\na PyTorch version that has been compiled with your version\nof the CUDA driver."
     ]
    }
   ],
   "source": [
    "# cpu to gpu \n",
    "x_gpu = x.cuda()\n",
    "x_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cpu to gpu \n",
    "x_cpu = x_gpu.cpu()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "192.4px",
    "left": "510px",
    "right": "20px",
    "top": "114px",
    "width": "505px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
