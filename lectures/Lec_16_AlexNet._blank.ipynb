{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lec_16_AlexNet\n",
    "<font size=5><b><b></font>\n",
    "<div align='right'> Hoe Sung Ryu ( 류 회 성 ) </div>\n",
    "    \n",
    "<img src= https://miro.medium.com/proxy/1*qyc21qM0oxWEuRaj-XJKcw.png width=70%>\n",
    "\n",
    "    \n",
    "---\n",
    "    \n",
    "Syllabus\n",
    "\n",
    "|Event Type|Date|Topic|\n",
    "|--:|:---:|:---|\n",
    "|1 |July 27| Environment setting and Python basic|\n",
    "|2 |July 28| Pytorch basic and Custom Data load |\n",
    "|3 |July 29| Traditional Machine Learning(1) |\n",
    "|4 |July 30| Traditional Machine Learning(2) |\n",
    "|5 |July 31| CNN(Convolutional Neural Network)(1)  |\n",
    "|6 |Aug 03| CNN(Convolutional NeuralNetwork)(2) |\n",
    "|7 |Aug 04|  RNN(Recurrent Neural Networks)(1) |\n",
    "|8 |Aug 05|  RNN(Recurrent Neural Networks)(2) |\n",
    "|9 |Aug 06|  Transfer learning(VGG pertained on ImageNEt for CIfar-10)| \n",
    "|10|Aug 07|**Mini_Kaggle**: Facial Expression Recognition on `AffectNet` | \n",
    "|11|Aug 08|`Awards` and `Closing`| \n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#CIFAR-10\" data-toc-modified-id=\"CIFAR-10-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>CIFAR 10</a></span></li><li><span><a href=\"#AlexNet\" data-toc-modified-id=\"AlexNet-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>AlexNet</a></span><ul class=\"toc-item\"><li><span><a href=\"#References\" data-toc-modified-id=\"References-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>References</a></span></li><li><span><a href=\"#SETTINGS\" data-toc-modified-id=\"SETTINGS-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>SETTINGS</a></span></li><li><span><a href=\"#Dataset-and-DataLoader\" data-toc-modified-id=\"Dataset-and-DataLoader-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Dataset and DataLoader</a></span></li><li><span><a href=\"#Model\" data-toc-modified-id=\"Model-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Model</a></span></li><li><span><a href=\"#Training\" data-toc-modified-id=\"Training-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>Training</a></span></li><li><span><a href=\"#Evaluation\" data-toc-modified-id=\"Evaluation-2.6\"><span class=\"toc-item-num\">2.6&nbsp;&nbsp;</span>Evaluation</a></span></li><li><span><a href=\"#Visualization\" data-toc-modified-id=\"Visualization-2.7\"><span class=\"toc-item-num\">2.7&nbsp;&nbsp;</span>Visualization</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR 10 \n",
    "<img src =https://cafe-and-cookies.tokyo/wp/wp-content/uploads/2019/03/img_5c828f2715196.png>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AlexNet \n",
    "\n",
    "- 60million parameters\n",
    "- Non-linearity : uses ReLU\n",
    "- new methods : dropout, data augmentation\n",
    "- 5 Convolutional Layers, 3 Fully-Connected layers, 1000-way softmax\n",
    "\n",
    "### References   \n",
    "- [1] Krizhevsky, Alex, Ilya Sutskever, and Geoffrey E. Hinton. \"[Imagenet classification with deep convolutional neural networks.](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)\" In Advances in Neural Information Processing Systems, pp. 1097-1105. 2012.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" data-title=\"\">\n",
    "  <h1><i class=\"fa fa-tasks\" aria-hidden=\"true\"></i> AlexNet with CIFAR-10\n",
    "  </h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-30T12:30:16.419063Z",
     "start_time": "2020-07-30T12:30:16.413287Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import Subset\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SETTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-30T12:30:17.037618Z",
     "start_time": "2020-07-30T12:30:17.033899Z"
    }
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "RANDOM_SEED = 1\n",
    "LEARNING_RATE = 0.0001\n",
    "BATCH_SIZE = 256\n",
    "NUM_EPOCHS = 40\n",
    "\n",
    "# Architecture\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "# Other\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-30T12:30:18.626349Z",
     "start_time": "2020-07-30T12:30:17.362777Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_indices = torch.arange(0, 48000)\n",
    "valid_indices = torch.arange(48000, 50000)\n",
    "\n",
    "\n",
    "train_transform = transforms.Compose([transforms.Resize((70, 70)),\n",
    "                                      transforms.RandomCrop((64, 64)),\n",
    "                                      transforms.ToTensor()])\n",
    "\n",
    "test_transform = transforms.Compose([transforms.Resize((70, 70)),\n",
    "                                     transforms.CenterCrop((64, 64)),\n",
    "                                     transforms.ToTensor()])\n",
    "\n",
    "train_and_valid = datasets.CIFAR10(root='data', \n",
    "                                   train=True, \n",
    "                                   transform=train_transform,\n",
    "                                   download=True)\n",
    "\n",
    "train_dataset = Subset(train_and_valid, train_indices)\n",
    "valid_dataset = Subset(train_and_valid, valid_indices)\n",
    "test_dataset = datasets.CIFAR10(root='data', \n",
    "                                train=False, \n",
    "                                transform=test_transform,\n",
    "                                download=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_loader = DataLoader(dataset=###TODO###, \n",
    "                          ###TODO###=BATCH_SIZE,\n",
    "                          num_workers=4,\n",
    "                          shuffle=True)\n",
    "\n",
    "valid_loader = DataLoader(dataset=###TODO###, \n",
    "                          ###TODO###=BATCH_SIZE,\n",
    "                          num_workers=4,\n",
    "                          shuffle=###TODO###)\n",
    "\n",
    "test_loader = DataLoader(dataset=###TODO###, \n",
    "                         ###TODO###=BATCH_SIZE,\n",
    "                         num_workers=4,\n",
    "                         shuffle=###TODO###)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-30T12:30:19.449443Z",
     "start_time": "2020-07-30T12:30:18.649274Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set:\n",
      "\n",
      "Image batch dimensions: torch.Size([256, 3, 64, 64])\n",
      "Image label dimensions: torch.Size([256])\n",
      "\n",
      "Validation Set:\n",
      "Image batch dimensions: torch.Size([256, 3, 64, 64])\n",
      "Image label dimensions: torch.Size([256])\n",
      "\n",
      "Testing Set:\n",
      "Image batch dimensions: torch.Size([256, 3, 64, 64])\n",
      "Image label dimensions: torch.Size([256])\n"
     ]
    }
   ],
   "source": [
    "# Checking the dataset\n",
    "print('Training Set:\\n')\n",
    "for images, labels in train_loader:  \n",
    "    print('Image batch dimensions:', images.size())\n",
    "    print('Image label dimensions:', labels.size())\n",
    "    break\n",
    "    \n",
    "# Checking the dataset\n",
    "print('\\nValidation Set:')\n",
    "for images, labels in valid_loader:  \n",
    "    print('Image batch dimensions:', images.size())\n",
    "    print('Image label dimensions:', labels.size())\n",
    "    break\n",
    "\n",
    "# Checking the dataset\n",
    "print('\\nTesting Set:')\n",
    "for images, labels in train_loader:  \n",
    "    print('Image batch dimensions:', images.size())\n",
    "    print('Image label dimensions:', labels.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "\n",
    "\n",
    "size = 3->64->192->384->->384->256->256\n",
    "```\n",
    "\n",
    "Fill the blank with the below options:\n",
    "===========================\n",
    "a. \n",
    "b. nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "c. nn.Conv2d(384, 256, kernel_size=3, padding=1)\n",
    "d. \n",
    "e. nn.Conv2d(64, 192, kernel_size=5, padding=2)\n",
    "f. nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2)\n",
    "g. nn.Conv2d(192, 384, kernel_size=3, padding=1)\n",
    "h. nn.Linear(4096, 4096),\n",
    "i. nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "j. nn.Dropout(0.5)\n",
    "k. nn.ReLU(inplace=True)\n",
    "==========================\n",
    "```\n",
    "\n",
    "### BLANK : conv ###\n",
    "### BLANK : ReLU ###\n",
    "### BLANK: POOL ###\n",
    "### BLANK: DROP ###\n",
    "### BLANK: FC ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-30T12:30:19.507246Z",
     "start_time": "2020-07-30T12:30:19.494049Z"
    }
   },
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            ### BLANK : conv ###\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            ### BLANK : conv ###\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            ### BLANK : conv ###\n",
    "            nn.ReLU(inplace=True),\n",
    "            ### BLANK : conv ###\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            ### BLANK: DROP ###,\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            ### BLANK: DROP ###\n",
    "            ### BLANK: FC ###,\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), 256 * 6 * 6)\n",
    "        logits = self.classifier(x)\n",
    "        probas = F.softmax(logits, dim=1)\n",
    "        return logits, probas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-30T12:30:19.939223Z",
     "start_time": "2020-07-30T12:30:19.553727Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "model = AlexNet(NUM_CLASSES)\n",
    "model.to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation "
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
